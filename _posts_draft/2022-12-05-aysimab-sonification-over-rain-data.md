---
layout: post
title: The sound of rain
date: 2022-12-07
categories: audio-programming
author: Alexander Wastnidge, Aysima Karcaaltincaba, Fabian Stordalen
image: /assets/image/2022_12_07_aysimab_dataset_cover.jpg
keywords: audio, sonification, programming
excerpt: "How we sonified the rainfall data."
---

Data driven sonification is bringing us huge opportunities regarding experimenting sound of "things". Things can be an unemployment rate as well as the number of deaths everyday. It can be anything.

As MCT Master students, we wanted to sonify rainfall timeseries data for our python project and apperantly rainfall has a good understanding of harmony!
For our project, we used rainfall timeseries data from [kaggle](https://www.kaggle.com/datasets/poojag718/rainfall-timeseries-data) which was collected from **Power Data Access Viewer.**

As it is described in kaggle website: <br/>
_The POWER Meteorological data is prediction or observation given by NASA's GMAO MERRA-2 assimilation model._
_The data collected is monthly frequency data for a particular latitude and longitude in Mumbai for the period 2000 â€“ 2020. The data consists of the following variables:_
- _Specific Humidity_
- _Relative Humidity_
- _Temperature_
- _Precipitation (The data consist of precipitation as monthly sum of rainfall )_

<figure>
   <img
      src="/assets/image/2022_12_07_aysimab_dataset_cover.jpg"
      style="max-height:400px; width:auto;" />
   <figcaption>Do you hear rain singing?</figcaption>
</figure>

### Sound corpus

Firstly we created sound corpus which had three synthesis. Two synthesis were two different musical lines in A Minor and one was the combination of chords responding to the same musical line. As first job for sonification, we calculated the duration of each note from the corresponding midi file by checking start and end time of the first note. Later we used this duration in order to slice the vaw file of musical line into multiple vaw files of each single note.

At this point, we had **7 vaw files for each synthesis with the note names A, B, C, D , E, F and G**.

### Mapping rainfall data

As second step, we extracted some arrays from our rain data like temperature, humidity and perceived temperature which was a multiplication of specific humidity and temperature. Afterwards we took these values as frequency and mapped them into midi numbers. By doing that, we were able to use "note_number_to_name" function of "pretty midi" library, in order to get note names for each array item.

At this point, we had multiple rain data which were mapped to note numbers and three different corpus data of vaw files with note names.

### Sonification process

As a final step of our sonification, we created three musical lines based on three synthesis and array data. For each corpus and rainfall array, we started iterating on the array and appending the sound of that note. One sonification was created by "temperature" data while the other two were created by "relative humidity" and "preceived temperature" data and all the data was ordered by time. 

And there was our sonification! We summed three output signals and had one sound which was generated by rainfall data! We built conductors from rainfall data features and they played a song for us together!


<!--Audio of sonification here: <div class="waveform" path="/assets/audio/xxx.mp3"></div>-->